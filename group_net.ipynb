{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 classes: [use, clean, close, do, flip, meet, open, pour, prick, sprinkle, insert, takeout, squeeze]\n",
      "\n",
      "['charge_cell_phone', 'light_candle', 'use_calculator', 'use_flash', 'write']\n",
      "['clean_glasses', 'wash_sponge']\n",
      "['close_juice_bottle', 'close_liquid_soap', 'close_milk', 'close_peanut_butter']\n",
      "['drink_mug', 'scratch_sponge', 'stir', 'tear_paper']\n",
      "['flip_pages', 'flip_sponge']\n",
      "['give_card', 'give_coin', 'handshake', 'high_five', 'receive_coin', 'toast_wine']\n",
      "['open_juice_bottle', 'open_letter', 'open_liquid_soap', 'open_milk', 'open_peanut_butter', 'open_soda_can', 'open_wallet']\n",
      "['pour_juice_bottle', 'pour_liquid_soap', 'pour_milk', 'pour_wine']\n",
      "['prick', 'scoop_spoon']\n",
      "['put_salt', 'sprinkle']\n",
      "['put_sugar', 'put_tea_bag']\n",
      "['read_letter', 'take_letter_from_enveloppe', 'unfold_glasses']\n",
      "['squeeze_paper', 'squeeze_sponge']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# based on https://danijar.com/variable-sequence-lengths-in-tensorflow/\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import functools\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os #os.environ\n",
    "\n",
    "from tensorflow.python.ops import rnn_cell, rnn\n",
    "from sklearn.metrics import confusion_matrix #compute confusion_matrix\n",
    "from matplotlib import pyplot as plt #display confusion_matrix\n",
    "from sklearn.model_selection import train_test_split #for training/validation set creation\n",
    "from myfunctions import action_to_group, get_group_labels, read_data, read_config, num_to_idx, plot_confusion_matrix\n",
    "\n",
    "#family = 'Object' \n",
    "family ='Motion'\n",
    "\n",
    "#directory = '/home/nathan/Documents/FYP_code/LSTM1_guillermo/grouping_1/'\n",
    "directory = '/home/nathan/Documents/FYP_code/LSTM1_guillermo/grouping_2/'\n",
    "\n",
    "label_location = directory + 'labels/' + family + '_group_labels.txt' \n",
    "directory_dataset = '/home/nathan/Documents/FYP_code/LSTM1_guillermo/data_nathan/'\n",
    "file_training = \"training.txt\"\n",
    "file_testing = \"testing.txt\" \n",
    "\n",
    "#Data Parameters\n",
    "feat_size = 63 #21 joints * 3 dimensions (xyz)\n",
    "padding_size = 300\n",
    "seq_max_len = padding_size # Sequence max length \n",
    "\n",
    "# Network Parameters\n",
    "learning_rate = 0.003\n",
    "n_epochs = 200\n",
    "batch_size = 20 # Try\n",
    "p_dropout = 0.5 # Try\n",
    "n_hidden = 100 # Try\n",
    "layers = 1 #Try\n",
    "\n",
    "#Load global variables (used everywhere)\n",
    "(atog, gtoa, g_labels) = action_to_group(label_location, family)\n",
    "groups_with_subnet =  [i for i, value in enumerate(gtoa) if len(value)>1]\n",
    "groups_without_subnet =  [i for i, value in enumerate(gtoa) if len(value)==1]\n",
    "num_classes = max(atog) + 1 #or len(g_labels) \n",
    "\n",
    "#Sanity check\n",
    "print (str(num_classes)+ ' classes: [' + ', '.join(g_labels) + ']\\n')\n",
    "location = directory + 'labels/name_of_labels_original.txt'\n",
    "for i in range(num_classes): #visualise the whole grouping of 45 actions at once as a nested list\n",
    "    print(get_group_labels(location,atog,i))\n",
    "    \n",
    "#For some debug\n",
    "with open(directory + 'labels/name_of_labels_original.txt') as f:\n",
    "    name_labels = np.asarray([word for line in f for word in line.split()])\n",
    "    \n",
    "print(groups_with_subnet)\n",
    "print(groups_without_subnet)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#26 Object\n",
    "\n",
    "var pubs =\n",
    "{\n",
    "    \"name\": \"Object\",\n",
    "    \"children\": [\n",
    "        {       \n",
    "            \"name\": \"sponge\",\"children\": [\n",
    "                {\"name\": \"flip\"},\n",
    "                {\"name\": \"scratch\"},\n",
    "                {\"name\": \"squeeze\"},\n",
    "                {\"name\": \"wash\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"spoon\",\"children\": [\n",
    "                {\"name\": \"put sugar\"},\n",
    "                {\"name\": \"scoop\"},\n",
    "                {\"name\": \"sprinkle\"},\n",
    "                {\"name\": \"stir\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"juice bottle\",\"children\": [\n",
    "                {\"name\": \"close\"},\n",
    "                {\"name\": \"open\"},\n",
    "                {\"name\": \"pour\"},\n",
    "            ]\n",
    "        },\n",
    "         {       \n",
    "            \"name\": \"liquid soap\",\"children\": [\n",
    "                {\"name\": \"close\"},\n",
    "                {\"name\": \"open\"},\n",
    "                {\"name\": \"pour\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"milk\",\"children\": [\n",
    "                {\"name\": \"close\"},\n",
    "                {\"name\": \"open\"},\n",
    "                {\"name\": \"pour\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"paper\",\"children\": [\n",
    "                {\"name\": \"read letter\"},\n",
    "                {\"name\": \"squeeze\"},\n",
    "                {\"name\": \"tear\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"glasses\",\"children\": [\n",
    "                {\"name\": \"clean\"},\n",
    "                {\"name\": \"unfold\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"peanut butter\",\"children\": [\n",
    "                {\"name\": \"close\"},\n",
    "                {\"name\": \"open\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"coin\",\"children\": [\n",
    "                {\"name\": \"give\"},\n",
    "                {\"name\": \"receive\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"hand\",\"children\": [\n",
    "                {\"name\": \"shake\"},\n",
    "                {\"name\": \"high five\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"letter\",\"children\": [\n",
    "                {\"name\": \"open\"},\n",
    "                {\"name\": \"take from enveloppe\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"cell phone\",\"children\": [\n",
    "                {\"name\": \"charge\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"mug\",\"children\": [\n",
    "                {\"name\": \"drink\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"pages\",\"children\": [\n",
    "                {\"name\": \"flip\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"card\",\"children\": [\n",
    "                {\"name\": \"give\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"candles\",\"children\": [\n",
    "                {\"name\": \"light\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"soda can\",\"children\": [\n",
    "                {\"name\": \"open\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"wallet\",\"children\": [\n",
    "                {\"name\": \"open\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"wine\",\"children\": [\n",
    "                {\"name\": \"pour\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"fork\",\"children\": [\n",
    "                {\"name\": \"prick\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"salt\",\"children\": [\n",
    "                {\"name\": \"put\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"tea bag\",\"children\": [\n",
    "                {\"name\": \"put\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"wine\",\"children\": [\n",
    "                {\"name\": \"toast\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"calculator\",\"children\": [\n",
    "                {\"name\": \"use\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"flash\",\"children\": [\n",
    "                {\"name\": \"use\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"pen\",\"children\": [\n",
    "                {\"name\": \"write\"},\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "\n",
    "\n",
    "    ]\n",
    "};"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#12 Object\n",
    "\n",
    "var pubs =\n",
    "{\n",
    "    \"name\": \"Object\",\n",
    "    \"children\": [\n",
    "        {       \n",
    "            \"name\": \"sponge\",\"children\": [\n",
    "                {\"name\": \"flip\"},\n",
    "                {\"name\": \"scratch\"},\n",
    "                {\"name\": \"squeeze\"},\n",
    "                {\"name\": \"wash\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"spoon\",\"children\": [\n",
    "                {\"name\": \"put sugar\"},\n",
    "                {\"name\": \"scoop\"},\n",
    "                {\"name\": \"sprinkle\"},\n",
    "                {\"name\": \"stir\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"juice bottle\",\"children\": [\n",
    "                {\"name\": \"close\"},\n",
    "                {\"name\": \"open\"},\n",
    "                {\"name\": \"pour\"},\n",
    "            ]\n",
    "        },\n",
    "         {       \n",
    "            \"name\": \"liquid soap\",\"children\": [\n",
    "                {\"name\": \"close\"},\n",
    "                {\"name\": \"open\"},\n",
    "                {\"name\": \"pour\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"milk\",\"children\": [\n",
    "                {\"name\": \"close\"},\n",
    "                {\"name\": \"open\"},\n",
    "                {\"name\": \"pour\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"paper\",\"children\": [\n",
    "                {\"name\": \"read letter\"},\n",
    "                {\"name\": \"squeeze\"},\n",
    "                {\"name\": \"tear\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"glasses\",\"children\": [\n",
    "                {\"name\": \"clean\"},\n",
    "                {\"name\": \"unfold\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"peanut butter\",\"children\": [\n",
    "                {\"name\": \"close\"},\n",
    "                {\"name\": \"open\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"coin\",\"children\": [\n",
    "                {\"name\": \"give\"},\n",
    "                {\"name\": \"receive\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"hand\",\"children\": [\n",
    "                {\"name\": \"shake\"},\n",
    "                {\"name\": \"high five\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"letter\",\"children\": [\n",
    "                {\"name\": \"open\"},\n",
    "                {\"name\": \"take from enveloppe\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"item\",\"children\": [\n",
    "                {\"name\": \"charge\"},\n",
    "                {\"name\": \"drink\"},\n",
    "                {\"name\": \"flip\"},\n",
    "                {\"name\": \"give\"},\n",
    "                {\"name\": \"light\"},\n",
    "                {\"name\": \"open\"},\n",
    "                {\"name\": \"open\"},\n",
    "                {\"name\": \"pour\"},\n",
    "                {\"name\": \"prick\"},\n",
    "                {\"name\": \"put\"},\n",
    "                {\"name\": \"put\"},\n",
    "                {\"name\": \"toast\"},\n",
    "                {\"name\": \"use\"},\n",
    "                {\"name\": \"use\"},\n",
    "                {\"name\": \"write\"},\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "\n",
    "\n",
    "    ]\n",
    "};"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#16 Motion\n",
    "\n",
    "var pubs =\n",
    "{\n",
    "    \"name\": \"Motion\",\n",
    "    \"children\": [\n",
    "        {       \n",
    "            \"name\": \"open\",\"children\": [\n",
    "                {\"name\": \"juice bottle\"},\n",
    "                {\"name\": \"letter\"},\n",
    "                {\"name\": \"liquid soap\"},\n",
    "                {\"name\": \"milk\"},\n",
    "                {\"name\": \"peanut butter\"},\n",
    "                {\"name\": \"soda can\"},\n",
    "                {\"name\": \"wallet\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"meet\",\"children\": [\n",
    "                {\"name\": \"card\"},\n",
    "                {\"name\": \"give coin\"},\n",
    "                {\"name\": \"receive coin\"},\n",
    "                {\"name\": \"handshake\"},\n",
    "                {\"name\": \"high five\"},\n",
    "                {\"name\": \"toast wine\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"use\",\"children\": [\n",
    "                {\"name\": \"charge cell phone\"},\n",
    "                {\"name\": \"light candle\"},\n",
    "                {\"name\": \"calculator\"},\n",
    "                {\"name\": \"spray\"},\n",
    "                {\"name\": \"write pen\"},\n",
    "            ]\n",
    "        },\n",
    "         {       \n",
    "            \"name\": \"close\",\"children\": [\n",
    "                {\"name\": \"juice bottle\"},\n",
    "                {\"name\": \"liquid soap\"},\n",
    "                {\"name\": \"milk\"},\n",
    "                {\"name\": \"peanut butter\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"pour\",\"children\": [\n",
    "                {\"name\": \"juice bottle\"},\n",
    "                {\"name\": \"liquid soap\"},\n",
    "                {\"name\": \"milk\"},\n",
    "                {\"name\": \"wine\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"take out\",\"children\": [\n",
    "                {\"name\": \"read letter\"},\n",
    "                {\"name\": \"letter from envelope\"},\n",
    "                {\"name\": \"unfold glasses\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"clean\",\"children\": [\n",
    "                {\"name\": \"glasses\"},\n",
    "                {\"name\": \"sponge\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"flip\",\"children\": [\n",
    "                {\"name\": \"pages\"},\n",
    "                {\"name\": \"sponge\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"prick\",\"children\": [\n",
    "                {\"name\": \"fork\"},\n",
    "                {\"name\": \"scoop spoon\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"sprinkle\",\"children\": [\n",
    "                {\"name\": \"put salt\"},\n",
    "                {\"name\": \"sprinkle\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"insert\",\"children\": [\n",
    "                {\"name\": \"sugar\"},\n",
    "                {\"name\": \"tea bag\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"squeeze\",\"children\": [\n",
    "                {\"name\": \"paper\"},\n",
    "                {\"name\": \"sponge\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"drink\",\"children\": [\n",
    "                {\"name\": \"mug\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"scratch\",\"children\": [\n",
    "                {\"name\": \"sponge\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"stir\",\"children\": [\n",
    "                {\"name\": \"spoon\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"tear\",\"children\": [\n",
    "                {\"name\": \"paper\"},\n",
    "            ]\n",
    "        },   \n",
    "\n",
    "    ]\n",
    "};"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#13 Motion\n",
    "\n",
    "var pubs =\n",
    "{\n",
    "    \"name\": \"Motion\",\n",
    "    \"children\": [\n",
    "        {       \n",
    "            \"name\": \"open\",\"children\": [\n",
    "                {\"name\": \"juice bottle\"},\n",
    "                {\"name\": \"letter\"},\n",
    "                {\"name\": \"liquid soap\"},\n",
    "                {\"name\": \"milk\"},\n",
    "                {\"name\": \"peanut butter\"},\n",
    "                {\"name\": \"soda can\"},\n",
    "                {\"name\": \"wallet\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"meet\",\"children\": [\n",
    "                {\"name\": \"card\"},\n",
    "                {\"name\": \"give coin\"},\n",
    "                {\"name\": \"receive coin\"},\n",
    "                {\"name\": \"handshake\"},\n",
    "                {\"name\": \"high five\"},\n",
    "                {\"name\": \"toast wine\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"use\",\"children\": [\n",
    "                {\"name\": \"charge cell phone\"},\n",
    "                {\"name\": \"light candle\"},\n",
    "                {\"name\": \"calculator\"},\n",
    "                {\"name\": \"spray\"},\n",
    "                {\"name\": \"write pen\"},\n",
    "            ]\n",
    "        },\n",
    "         {       \n",
    "            \"name\": \"close\",\"children\": [\n",
    "                {\"name\": \"juice bottle\"},\n",
    "                {\"name\": \"liquid soap\"},\n",
    "                {\"name\": \"milk\"},\n",
    "                {\"name\": \"peanut butter\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"pour\",\"children\": [\n",
    "                {\"name\": \"juice bottle\"},\n",
    "                {\"name\": \"liquid soap\"},\n",
    "                {\"name\": \"milk\"},\n",
    "                {\"name\": \"wine\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"take out\",\"children\": [\n",
    "                {\"name\": \"read letter\"},\n",
    "                {\"name\": \"letter from envelope\"},\n",
    "                {\"name\": \"unfold glasses\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"clean\",\"children\": [\n",
    "                {\"name\": \"glasses\"},\n",
    "                {\"name\": \"sponge\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"flip\",\"children\": [\n",
    "                {\"name\": \"pages\"},\n",
    "                {\"name\": \"sponge\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"prick\",\"children\": [\n",
    "                {\"name\": \"fork\"},\n",
    "                {\"name\": \"scoop spoon\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"sprinkle\",\"children\": [\n",
    "                {\"name\": \"put salt\"},\n",
    "                {\"name\": \"sprinkle\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"insert\",\"children\": [\n",
    "                {\"name\": \"sugar\"},\n",
    "                {\"name\": \"tea bag\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"squeeze\",\"children\": [\n",
    "                {\"name\": \"paper\"},\n",
    "                {\"name\": \"sponge\"},\n",
    "            ]\n",
    "        },\n",
    "        {       \n",
    "            \"name\": \"do\",\"children\": [\n",
    "                {\"name\": \"drink mug\"},\n",
    "                {\"name\": \"scratch sponge\"},\n",
    "                {\"name\": \"stir spoon\"},\n",
    "                {\"name\": \"tear paper\"},\n",
    "            ]\n",
    "        },\n",
    "           \n",
    "\n",
    "    ]\n",
    "};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function definitions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Called to load training/testing data \n",
    "def create_dataset(filename, group_number):\n",
    "    # dataset is organized as NxLxD (N = num samples, L temporal length with padding, D feature dimension\n",
    "    # labels is NxY where Y is one hot label vector\n",
    "    \n",
    "    # -3 sends back labels as actions number (0..45) with one hot enconding (000..1..00)\n",
    "    # -2 sends back labels as actions number (0..45) with no one hot enconding (1 or 2 or 45)\n",
    "    # -1 sends back labels as groups number (0..12or26) with one hot encoding (000..1..00)\n",
    "    # 0> sends back labels of only this group with one hot enconding\n",
    "\n",
    "    dataset, labels, lengths = [], [], []\n",
    "    files = read_config(filename)\n",
    "    \n",
    "    if group_number == -3: #standard 45 actions RNN\n",
    "        num_classes = 45\n",
    "    elif group_number == -2: #groupRNN to subnets (testing phase)\n",
    "        #num_classes = 45 #not needed in the function when -2 activated\n",
    "        pass\n",
    "    elif group_number == -1: #groupRNN\n",
    "        num_classes = max(atog) + 1 \n",
    "        #pass\n",
    "    else: #subnets\n",
    "        list_actions = gtoa[group_number] #gives list of actions in current group number\n",
    "        num_classes = len(list_actions)\n",
    "        \n",
    "    for i in files:\n",
    "        \n",
    "        if group_number == -3:  #standard 45 actions RNN\n",
    "            \n",
    "            tmp_data = read_data(directory_dataset + i[0]) #i[0] =  a01s01r01.txt (for eg)\n",
    "            num =  int( i[1] )\n",
    "            tmp_labels = np.transpose(num_to_idx(num, num_classes)) #one hot encoding\n",
    "        \n",
    "        elif group_number == -2: #Feed output of groupRNN to pre-trained subnet (testing phase)\n",
    "            \n",
    "            tmp_data = read_data(directory_dataset + i[0]) #i[0] =  a01s01r01.txt (for eg)\n",
    "            tmp_labels = int(i[1]) #will one hot later as first need to dispatch data to relevant subnet using labels\n",
    "        \n",
    "        elif group_number == -1: #Build groupRNN\n",
    "            \n",
    "            tmp_data = read_data(directory_dataset + i[0]) \n",
    "            num =  atog[ int( i[1] )] #only used for one hot encoding in the line below\n",
    "            tmp_labels = np.transpose(num_to_idx(num, num_classes)) \n",
    "            #i[0] =  a01s01r01.txt (for eg)\n",
    "            #i[1] = number between 0 and 44 (or as many classes there is)\n",
    "            #tmp_labels = [0, 0, 1, 0, .. 0] = one-hot encoding of class value\n",
    "            #tmp_data = list with variable len around 300 & each item in the list is a nested list of len 63 (=feat_size)\n",
    "        \n",
    "        else: #Build subnet RNN\n",
    "            \n",
    "            num = int( i[1] ) #original action number\n",
    "            if num in list_actions: #select data only if belongs to group \n",
    "                tmp_data = read_data(directory_dataset + i[0]) #add to dataset if part of the group\n",
    "                tmp_labels = np.transpose(num_to_idx(list_actions.index(num), num_classes)) #add labels as well     \n",
    "            else: continue\n",
    "            \n",
    "        if len(tmp_data)<300: #why 300, is that the longest sequence ? 300 = padding_size btw...\n",
    "            \n",
    "            #records tmp_data initial length before padding\n",
    "            #pads tmp_data with zeros until padding_size (300) so len(tmp_data) = 300 always with len 63 items\n",
    "                \n",
    "            lengths.append(len(tmp_data))\n",
    "            tmp_data.extend([ [0.0] * feat_size ] * (padding_size - len(tmp_data)))  \n",
    "\n",
    "            dataset.append(tmp_data)\n",
    "            labels.append(tmp_labels) \n",
    "        \n",
    "    # all 0..565 lists with item as nested lists of size (300, 26, 1)\n",
    "    return dataset, labels, lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Called once when training RNN\n",
    "def batch_generation(data,labels,lengths):\n",
    "    \n",
    "    num_classes = np.size(labels,1) #labels is a one hot encoded numpy array. This returns number of columns (=groups).\n",
    "    \n",
    "    nsamples,_,_ = data.shape\n",
    "\n",
    "    indices = np.arange(nsamples) #np.arange(3) -> array([0, 1, 2])\n",
    "    np.random.shuffle(indices) #shuffle the indices\n",
    "    num_batches = int(np.floor(nsamples/batch_size)) #round to inferior number so = 0 if batch_size bigger than nsamples\n",
    "    not_exact = 0\n",
    "\n",
    "    if nsamples%batch_size != 0: #happens all the time unless nsamples is lucky multiple of batch_size\n",
    "        not_exact = 1\n",
    "    \n",
    "    #declare empty arrays to contain the batches, dimensions are right\n",
    "    batches_data = np.empty(shape=[num_batches+not_exact,batch_size,padding_size,feat_size])\n",
    "    batches_labels = np.empty(shape=[num_batches+not_exact,batch_size,num_classes]) \n",
    "    batches_lengths = np.empty(shape=[num_batches + not_exact, batch_size],dtype=np.int32)\n",
    "\n",
    "    for x in range(num_batches):\n",
    "        batches_data[x, :, :, :] = data[indices[batch_size*x:batch_size*(x+1)], :, :]\n",
    "        batches_labels[x,:,:] = labels[indices[batch_size*x:batch_size*(x+1)], :]\n",
    "        batches_lengths[x,:] = lengths[indices[batch_size*x:batch_size*(x+1)]]\n",
    "\n",
    "    if not_exact > 0:\n",
    "        \n",
    "        to_complete = nsamples%batch_size\n",
    "        \n",
    "        #nsamples is too small, reuse the samples from previous batch, taken randomly to complete this batch\n",
    "        tmp_random = np.random.randint(0,nsamples,batch_size-to_complete) # we complete last batch with random samples\n",
    "        #prints list of indices it will take randomly\n",
    "        \n",
    "        #[num_batches] refers to the last batch that is not complete\n",
    "        tmp_data = data[indices[batch_size*num_batches:batch_size*num_batches+to_complete],:,:]\n",
    "        batches_data[num_batches]=np.concatenate((tmp_data,data[tmp_random,:,:]),axis=0)\n",
    "\n",
    "        tmp_labels = labels[indices[batch_size*num_batches:batch_size*num_batches+to_complete],:]\n",
    "        batches_labels[num_batches] = np.concatenate((tmp_labels,labels[indices[tmp_random],:]))\n",
    "        \n",
    "        tmp_lengths = lengths[indices[batch_size*num_batches:batch_size*num_batches+to_complete]]\n",
    "        batches_lengths[num_batches] = np.concatenate((tmp_lengths,lengths[indices[tmp_random]]))\n",
    "\n",
    "    return batches_data, batches_labels, batches_lengths, num_batches+not_exact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dynamicRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamicRNN(x, seqlen, weights, biases, keep_prob):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Permuting batch_size and n_steps\n",
    "    x = tf.transpose(x, [1, 0, 2])\n",
    "    # Reshaping to (n_steps*batch_size, n_input)\n",
    "    x = tf.reshape(x, [-1, feat_size])\n",
    "    # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.split(x, seq_max_len, 0) # tf.split(value, num_or_size_splits, axis)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "    \n",
    "    #Operator adding dropout to inputs and outputs of the given cell.\n",
    "    lstm_cell_dropout = rnn_cell.DropoutWrapper(lstm_cell, output_keep_prob = keep_prob) \n",
    "    \n",
    "    #Added to have 2 layers LSTM, not used here.\n",
    "    final_cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell_dropout] * layers)\n",
    "\n",
    "    # Get lstm cell output, providing 'sequence_length' will perform dynamic calculation.\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(final_cell, x, dtype=tf.float32, sequence_length=seqlen)\n",
    "    \n",
    "    # When performing dynamic calculation, we must retrieve the last\n",
    "    # dynamically computed output, i.e, if a sequence length is 10, we need\n",
    "    # to retrieve the 10th output.\n",
    "    # However TensorFlow doesn't support advanced indexing yet, so we build\n",
    "    # a custom op that for each sample in batch size, get its length and\n",
    "    # get the corresponding relevant output.\n",
    "\n",
    "    # 'outputs' is a list of output at every timestep, we pack them in a Tensor\n",
    "    # and change back dimension to [batch_size, n_step, n_input]\n",
    "    outputs = tf.stack(outputs)\n",
    "    outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "\n",
    "    # Hack to build the indexing and retrieve the right output.\n",
    "    batch_size = tf.shape(outputs)[0]\n",
    "    # Start indices for each sample\n",
    "    index = tf.range(0, batch_size) * seq_max_len + (seqlen - 1)\n",
    "    # Indexing\n",
    "    outputs = tf.gather(tf.reshape(outputs, [-1, n_hidden]), index)\n",
    "\n",
    "    # Linear activation, using outputs computed above\n",
    "    return tf.matmul(outputs, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doMyRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doMyRNN(family, group_number):\n",
    "    \n",
    "    # group_number = \n",
    "    # -3 training stanard 45 actions RNN\n",
    "    # -2 never\n",
    "    # -1 training groupRNN\n",
    "    # 0> training subnet\n",
    "\n",
    "    # ==========\n",
    "    #   MODEL\n",
    "    # ==========\n",
    "    print('in MODEL')\n",
    "\n",
    "    tf.reset_default_graph() #Clear computational graph to prevent error\n",
    "    \n",
    "    # Load training and testing data\n",
    "    train_data, train_labels, train_lengths = create_dataset(file_training, group_number)\n",
    "    test_data, test_labels, test_lengths = create_dataset(file_testing, group_number)\n",
    "    \n",
    "    #cast to numpy array\n",
    "    train_data = np.asarray(train_data)\n",
    "    train_labels = np.asarray(train_labels)\n",
    "    train_lengths = np.asarray(train_lengths)\n",
    "    test_data = np.asarray(test_data)\n",
    "    test_labels = np.asarray(test_labels)\n",
    "    test_lengths = np.asarray(test_lengths)\n",
    "    \n",
    "    #Set validation/training split\n",
    "    tr_data, val_data, tr_labels, val_labels, tr_lengths, val_lengths = train_test_split(train_data, train_labels, train_lengths, \n",
    "                                                                                            test_size=0.2, random_state=42, stratify=train_labels)\n",
    "\n",
    "    (samples, rows, row_size) = train_data.shape\n",
    "\n",
    "    n_classes = np.size(train_labels,1)\n",
    "\n",
    "    # tf Graph input\n",
    "    x = tf.placeholder(\"float\", [None, seq_max_len, feat_size], name=\"x\")\n",
    "    y = tf.placeholder(\"float\", [None, n_classes], name=\"y\")\n",
    "\n",
    "    # A placeholder for indicating each sequence length\n",
    "    seqlen = tf.placeholder(tf.int32, [None], name=\"seqlen\")\n",
    "\n",
    "    # Define weights\n",
    "    weights = {\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "    # ==========\n",
    "    #   LAUNCH\n",
    "    # ==========\n",
    "    print('in LAUNCH')\n",
    "\n",
    "    pred = dynamicRNN(x, seqlen, weights, biases, keep_prob)\n",
    "\n",
    "    # Evaluate model \n",
    "    prediction = tf.argmax(pred, axis=1, name=\"prediction\") # for each prediction, keep class with highest level of confidence (tests X classes)\n",
    "    correct_pred = tf.equal(prediction, tf.argmax(y,1)) #output 0 & 1 vector, y is supposed to have true labels\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32)) #mean of above\n",
    "    \n",
    "    #Create a saver object which will save all the variables\n",
    "    #saver = tf.train.Saver()\n",
    "\n",
    "    # ============\n",
    "    #   OPTIMIZE\n",
    "    # ============\n",
    "    print('in OPTIMIZE \\n')\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = pred, labels = y))\n",
    "    # optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    # optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # Initializing the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    #Create a saver object which will save all the variables\n",
    "    saver = tf.train.Saver() \n",
    "    if group_number == -3 :\n",
    "        saved_path = '/home/nathan/Documents/FYP_code/LSTM1_guillermo/grouping_0/'\n",
    "    elif group_number == -1 :\n",
    "        saved_path = directory + 'saved_sessions/group_RNN/' + family \n",
    "    else:\n",
    "        saved_path = directory + 'saved_sessions/subnets/' + family + '/subnet_' + str(group_number)\n",
    "\n",
    "    # Launch the graph\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        sess.run(init)\n",
    "\n",
    "        max_acc = 0.0;\n",
    "        max_epoch = 0;\n",
    "        best_labels = []\n",
    "\n",
    "        # Keep training until reach max iterations\n",
    "        for epoch in range(n_epochs):\n",
    "            \n",
    "            (batch_x, batch_y, batch_seqlen, n_batches) = batch_generation(tr_data, tr_labels, tr_lengths)\n",
    "\n",
    "            start = time.time()\n",
    "\n",
    "            for i in range(n_batches):\n",
    "\n",
    "                # Run optimization op (backprop)\n",
    "                sess.run(optimizer, feed_dict={x: batch_x[i,:,:,:], y: batch_y[i,:,:],\n",
    "                                               seqlen: batch_seqlen[i,:], keep_prob: p_dropout})\n",
    "\n",
    "            # Test accuracy on this epoch    \n",
    "            validation_acc = sess.run(accuracy, feed_dict={x: val_data, y: val_labels, seqlen: val_lengths, keep_prob: 1.0})\n",
    "\n",
    "            #Save best validation results\n",
    "            if validation_acc > max_acc: \n",
    "                \n",
    "                max_acc = validation_acc; max_epoch = epoch\n",
    "                    \n",
    "                #Save best model of the NN\n",
    "                saver.save(sess, saved_path)\n",
    "                print('Saved subnet at epoch ' + str(epoch) + ' at ' + saved_path)\n",
    "\n",
    "                print('Epoch {:2d} validation accuracy {:3.1f}% in {:3.1f} seconds'.format(epoch, 100 * validation_acc, time.time() - start))\n",
    "                print('max_acc {:3.1f}% at epoch {:2d} \\n'.format(max_acc*100, max_epoch))\n",
    "            \n",
    "            #Stop training when accuracy is maximum\n",
    "            if max_acc == 1: \n",
    "                print('Reached 100% accuracy -> exit training \\n')\n",
    "                break\n",
    "             \n",
    "        print (\"Optimization Finished! \\n\")\n",
    "        \n",
    "        #trying\n",
    "        A, B =  sess.run([pred, prediction], feed_dict={x: test_data, y: test_labels, seqlen: test_lengths, keep_prob: 1.0})\n",
    "        C = test_labels\n",
    "        return A, B, C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confusion_mtx & confidence_probability_g & compute_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display confusion matrix\n",
    "def confusion_mtx(true, pred, labels):\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cnf_matrix = confusion_matrix(pred, true)\n",
    "    np.set_printoptions(precision=1)\n",
    "    \n",
    "    s=14\n",
    "    \n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure(figsize=(s,s), dpi=150)\n",
    "    plot_confusion_matrix(cnf_matrix, classes=labels,\n",
    "                          title='Confusion matrix, without normalization')\n",
    "    plt.savefig('conf_mat_raw.png', bbox_inches='tight', dpi='figure')\n",
    "\n",
    "    # Plot normalized confusion matrix\n",
    "    plt.figure(figsize=(s,s), dpi=150)\n",
    "    plot_confusion_matrix(cnf_matrix, classes=labels, normalize=True,\n",
    "                          title='Normalized confusion matrix')\n",
    "    plt.savefig('conf_mat_normalised.png', bbox_inches='tight', dpi='figure')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "#Display confidence level bar histogram \n",
    "def confidence_probability_g (scores, pred_class, true_class, g_labels):\n",
    "    \n",
    "    format_scores = scores - np.amin(scores)\n",
    "    format_scores = format_scores / np.amax(format_scores)\n",
    "    \n",
    "    #y = scores\n",
    "    y = format_scores #probabilities made from normalising on this 1 score (not on the 569 scores)\n",
    "    x = range(len(scores)) #as much scores as there is in y (45)\n",
    "    \n",
    "    plt.figure(figsize=(20,4))\n",
    "    \n",
    "    barlist = plt.bar(x,y, width=0.7)\n",
    "    \n",
    "    num_classes = len(g_labels)\n",
    "\n",
    "    import randomcolor\n",
    "    colors = randomcolor.RandomColor().generate(count=num_classes) #as many group or actions    \n",
    "    for i in range(len(barlist)): barlist[i].set_color(colors[i])\n",
    "    \n",
    "    plt.title('Predicted class ' + str(pred_class) + ' ' + g_labels[pred_class] \n",
    "                 + ' for class ' + str(true_class) + ' ' + g_labels[true_class],\n",
    "                 fontsize=18)\n",
    "    \n",
    "    plt.xticks(x, g_labels, rotation=90, fontsize=18)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    #ToDo\n",
    "    # Be able to know the name of sample seq that fails \n",
    "    \n",
    "def compute_accuracy(groups, pred_labels, test_labels):\n",
    "    \n",
    "    indices = [index for index, value in enumerate(pred_labels) if value in groups]\n",
    "    p, t = pred_labels[indices], test_labels[indices]\n",
    "    group_t = [atog[value] for value in t] #convert t labels from action to group number for comparison with p\n",
    "    \n",
    "    correct_pred = np.equal(p, group_t)\n",
    "    \n",
    "    return correct_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "useSubnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def useSubnet(group_number, pred_labels, test_data, test_labels, test_lenghts):\n",
    "    \n",
    "    #Alreaedy done in create dataset by using: (sub_test_data, sub_test_labels, sub_test_lengths) = create_dataset(file_testing, group_number)\n",
    "    #Select relevant subset of data, labels and lengths to use on subnet\n",
    "    indices = [index for index, value in enumerate(pred_labels) if value == group_number]\n",
    "    (sub_test_data, sub_test_labels, sub_test_lengths) = test_data[indices], test_labels[indices], test_lengths[indices]\n",
    "    #sub_test_labels is the subnet truth label to compare to subnet output\n",
    "    \n",
    "    tf.reset_default_graph() #Clear computational graph to prevent error\n",
    "    \n",
    "    #Load pre-trained subnet\n",
    "    sess=tf.Session()    \n",
    "    location = directory + 'saved_sessions/subnets/' + family + '/subnet_' + str(group_number)\n",
    "    saver = tf.train.import_meta_graph(location + \".meta\")\n",
    "    saver.restore(sess, location)\n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    #Import variables\n",
    "    x = graph.get_tensor_by_name(\"x:0\")\n",
    "    y = graph.get_tensor_by_name(\"y:0\")\n",
    "    seqlen = graph.get_tensor_by_name(\"seqlen:0\")\n",
    "    keep_prob = graph.get_tensor_by_name(\"keep_prob:0\")\n",
    "    \n",
    "    #Pass test samples through RNN\n",
    "    feed_dict={x: sub_test_data, seqlen: sub_test_lengths, keep_prob: 1.0} \n",
    "    prediction = graph.get_tensor_by_name(\"prediction:0\")\n",
    "    sub_pred_labels = sess.run(prediction, feed_dict) \n",
    "    \n",
    "    #Convert output back to original action number \n",
    "    list_actions = gtoa[group_number] \n",
    "    original_sub_pred_labels = [list_actions[i] for i in sub_pred_labels] \n",
    "    #assumes number of subnet output is same order as actions in gtoa...\n",
    "    \n",
    "    #Compute results\n",
    "    correct_pred = np.equal(original_sub_pred_labels, sub_test_labels) #output 0 & 1 vector\n",
    "    accuracy_with = np.mean(correct_pred)\n",
    "    \n",
    "    print(\"Accuracy subnet %i %s is %.2f %%\" % (group_number, g_labels[group_number], float(100*accuracy_with)) )\n",
    "    #onfusion_mtx(original_sub_pred_labels, sub_test_labels, g_labels[group_number])\n",
    "    \n",
    "    return correct_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "useGroupRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def useGroupRNN():\n",
    "    \n",
    "    (test_data, test_labels, test_lengths) = create_dataset(file_testing, -1)\n",
    "    true_labels = np.asarray( [ np.where(r==1)[0][0] for r in test_labels ], dtype=np.int64) #one hot to action number\n",
    "    \n",
    "    tf.reset_default_graph() #Clear computational graph to prevent error\n",
    "    \n",
    "    #Load pre-trained subnet\n",
    "    sess=tf.Session()    \n",
    "    location = directory + 'saved_sessions/group_RNN/' + family \n",
    "    saver = tf.train.import_meta_graph(location + \".meta\")\n",
    "    saver.restore(sess, location)\n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    #Import variables\n",
    "    x = graph.get_tensor_by_name(\"x:0\")\n",
    "    y = graph.get_tensor_by_name(\"y:0\")\n",
    "    seqlen = graph.get_tensor_by_name(\"seqlen:0\")\n",
    "    keep_prob = graph.get_tensor_by_name(\"keep_prob:0\")\n",
    "    \n",
    "    #Pass test samples through RNN\n",
    "    feed_dict={x: test_data, seqlen: test_lengths, keep_prob: 1.0} \n",
    "    prediction = graph.get_tensor_by_name(\"prediction:0\")\n",
    "    pred_labels = sess.run(prediction, feed_dict) \n",
    "    # pred_labels = \n",
    "    \n",
    "    #Compute results\n",
    "    correct_pred = np.equal(pred_labels, true_labels) #output 0 & 1 vector\n",
    "    accuracy = np.mean(correct_pred)\n",
    "    print(\"Accuracy groupRNN %s with %i classes is %.2f %%\" % (family, num_classes, float(100*accuracy))) \n",
    "    confusion_mtx(true_labels, pred_labels, g_labels)\n",
    "    \n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "useStandardRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def useStandardRNN():\n",
    "    \n",
    "    (test_data, test_labels, test_lengths) = create_dataset(file_testing, -3) #sends back 45 actions and one hot labels\n",
    "    true_labels = np.asarray( [ np.where(r==1)[0][0] for r in test_labels ], dtype=np.int64) #one hot to action number\n",
    "    \n",
    "    tf.reset_default_graph() #Clear computational graph to prevent error\n",
    "    \n",
    "    #Load pre-trained subnet\n",
    "    sess=tf.Session()    \n",
    "    location = '/home/nathan/Documents/FYP_code/LSTM1_guillermo/grouping_0/'\n",
    "    saver = tf.train.import_meta_graph(location + \".meta\")\n",
    "    saver.restore(sess, location)\n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    #Import variables\n",
    "    x = graph.get_tensor_by_name(\"x:0\")\n",
    "    y = graph.get_tensor_by_name(\"y:0\")\n",
    "    seqlen = graph.get_tensor_by_name(\"seqlen:0\")\n",
    "    keep_prob = graph.get_tensor_by_name(\"keep_prob:0\")\n",
    "    \n",
    "    #Pass test samples through RNN\n",
    "    feed_dict={x: test_data, seqlen: test_lengths, keep_prob: 1.0} \n",
    "    prediction = graph.get_tensor_by_name(\"prediction:0\")\n",
    "    pred_labels = sess.run(prediction, feed_dict) \n",
    "    \n",
    "    # Extract label names from text file\n",
    "    with open(directory + 'labels/name_of_labels_original.txt') as f:\n",
    "        name_labels = [word for line in f for word in line.split()]\n",
    "    \n",
    "    #Compute results\n",
    "    correct_pred = np.equal(pred_labels, true_labels) #output 0 & 1 vector\n",
    "    accuracy = np.mean(correct_pred)\n",
    "    num_classes = max(true_labels)+1 #should be 45\n",
    "    print(\"\\n Accuracy groupRNN %s with %i classes is %.2f %% \\n\" % (family, num_classes, float(100*accuracy))) \n",
    "    confusion_mtx(true_labels, pred_labels, name_labels)\n",
    "    \n",
    "    return pred_labels, true_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate_grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_grouping (pred_labels, true_labels, atog, g_labels, family):\n",
    "    \n",
    "    num_g = len(g_labels)\n",
    "    \n",
    "    #Convert labels from action to group\n",
    "    true_g_labels = np.asarray([atog[i] for i in true_labels])\n",
    "    pred_g_labels = np.asarray([atog[i] for i in pred_labels])\n",
    "    \n",
    "    #Calculate accuracy\n",
    "    correct_pred = np.equal(true_g_labels, pred_g_labels) #output 0 & 1 vector\n",
    "    accuracy_g = np.mean(correct_pred) #mean of above\n",
    "    print('Interpreted group %s Accuracy %.2f %% with %i groups' % (family, float(100*accuracy_g), num_g))\n",
    "    \n",
    "    confusion_mtx(true_g_labels, pred_g_labels, g_labels)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execution**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard 45 actions RNN**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RNN & save\n",
    "scores, pred_labels, true_labels = doMyRNN(family, -3) #family argument ignored if you pass -3\n",
    "\n",
    "#save scores"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Import RNN and test\n",
    "pred_labels, true_labels = useStandardRNN()\n",
    "\n",
    "#save pred and true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load scores pred true labels\n",
    "print(scores.shape) #should be 595*45\n",
    "location = '/home/nathan/Documents/FYP_code/LSTM1_guillermo/RNN_embedding/'\n",
    "np.save(location+'scores_45', scores) \n",
    "np.save(location+'pred_labels', pred_labels) \n",
    "np.save(location+'true_labels', true_labels) \n",
    "#confidence_probability_g (scores, pred_class, true_class, name_labels) #pass name_label to make it act on 45 groups (of 1 actions)\n",
    "# move the above to kmeans part..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-75d82239b7f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#one hot to action number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/nathan/Documents/FYP_code/LSTM1_guillermo/RNN_embedding/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'true_labels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorrect_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#output 0 & 1 vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "\n",
    "location = '/home/nathan/Documents/FYP_code/LSTM1_guillermo/RNN_embedding/'\n",
    "np.save(location+'true_labels', true_labels) \n",
    "correct_pred = np.equal(pred_labels, true_labels) #output 0 & 1 vector\n",
    "accuracy = np.mean(correct_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpret results if had been part of a group\n",
    "\n",
    "familyA = 'Object' \n",
    "#familyA ='Motion'\n",
    "directoryA = '/home/nathan/Documents/FYP_code/LSTM1_guillermo/grouping_1/'\n",
    "#directoryA = '/home/nathan/Documents/FYP_code/LSTM1_guillermo/grouping_2/'\n",
    "\n",
    "label_locationA = directoryA + 'labels/' + familyA + '_group_labels.txt' \n",
    "(atogA, _, g_labelsA) = action_to_group(label_locationA, familyA)\n",
    "evaluate_grouping (pred_labels, true_labels, atogA, g_labelsA, familyA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execution - Group RNN **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train group RNN on classifying the object group\n",
    "doMyRNN(family, -1) #-1 as this is a main group net (not subnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyze group RNN results\n",
    "pred_labels = useGroupRNN()\n",
    "\n",
    "#Save output to feed to subnet\n",
    "location = directory + 'results/group_RNN/' + family + '/'\n",
    "np.save(location + 'pred_labels.npy', pred_labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subnets RNN **"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#1. Train all subnets with a for loop and save them all\n",
    "#2. Import each as pre-trained model\n",
    "#3. Gather relevant output of groupRNN \n",
    "#4. Feed it to subnet\n",
    "#5. Get accuracy of each subnet and overall accuracy, including the outputs that did not get a subnet (1 action groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train subnets independently of group RNN \n",
    "\n",
    "#Build a subnet for all groups\n",
    "n_epochs = 100 #smaller training for smaller nets\n",
    "for group_number in groups_with_subnet:\n",
    "    \n",
    "    print('Group '+str(group_number)+' '+g_labels[group_number])\n",
    "    \n",
    "    doMyRNN(family, group_number) #Trained subnet are saved in doMyRNN\n",
    "    #Subnets are just like the orginal RNN but with a selected number of training samples from training.txt and testing.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Evaluate the subnet after its training\n",
    "    #acc = np.mean(np.equal(true_labels, pred_labels))\n",
    "    #print('Group %i \"%s\" - %s - accuracy: %.2f %%' % (group_number, g_labels[group_number], group_sub_labels, float(100*acc)))\n",
    "    #print(pred_labels); print(true_labels); print(np.equal(true_labels, pred_labels))\n",
    "    #location = directory + 'labels/name_of_labels_original.txt'\n",
    "    #group_sub_labels = get_group_labels(location, atog, group_number) #labels of classes (inside this group)\n",
    "    #confusion_mtx(true_labels, pred_labels, group_sub_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final group+subnet RNN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data & Compute groupRNN accuracy on 1 action and multi action groups\n",
    "\n",
    "#Obtain all original data\n",
    "(test_data, test_labels, test_lengths) = create_dataset(file_testing, -2)\n",
    "test_data, test_labels, test_lengths = np.asarray(test_data), np.asarray(test_labels), np.asarray(test_lengths) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Link groupRNN output to subnets input using pred_labels\n",
    "location = directory + 'results/group_RNN/' + family + '/'\n",
    "pred_labels = np.load(location + 'pred_labels.npy') \n",
    "\n",
    "if not groups_without_subnet: #means list is empty (no 1 action groups)\n",
    "    correct_pred_without, accuracy_without = [], 0\n",
    "else: #1 action groups exist\n",
    "    correct_pred_without = compute_accuracy(groups_without_subnet, pred_labels, test_labels)\n",
    "    accuracy_without = np.mean(correct_pred_without) \n",
    "correct_pred_with = compute_accuracy(groups_with_subnet, pred_labels, test_labels)\n",
    "accuracy_with = np.mean(correct_pred_with) \n",
    "print(\"Accuracy of groupRNN only on 1 and multi action groups: %.2f%% and %.2f%% \" % (float(100*accuracy_without), float(100*accuracy_with)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now using subnets for groups [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "INFO:tensorflow:Restoring parameters from /home/nathan/Documents/FYP_code/LSTM1_guillermo/grouping_2/saved_sessions/subnets/Motion/subnet_0\n",
      "Accuracy subnet 0 use is 87.88 %\n",
      "INFO:tensorflow:Restoring parameters from /home/nathan/Documents/FYP_code/LSTM1_guillermo/grouping_2/saved_sessions/subnets/Motion/subnet_1\n",
      "Accuracy subnet 1 clean is 84.62 %\n",
      "INFO:tensorflow:Restoring parameters from /home/nathan/Documents/FYP_code/LSTM1_guillermo/grouping_2/saved_sessions/subnets/Motion/subnet_2\n",
      "Accuracy subnet 2 close is 71.43 %\n",
      "INFO:tensorflow:Restoring parameters from /home/nathan/Documents/FYP_code/LSTM1_guillermo/grouping_2/saved_sessions/subnets/Motion/subnet_3\n",
      "Accuracy subnet 3 do is 78.72 %\n",
      "INFO:tensorflow:Restoring parameters from /home/nathan/Documents/FYP_code/LSTM1_guillermo/grouping_2/saved_sessions/subnets/Motion/subnet_4\n",
      "Accuracy subnet 4 flip is 83.33 %\n",
      "INFO:tensorflow:Restoring parameters from /home/nathan/Documents/FYP_code/LSTM1_guillermo/grouping_2/saved_sessions/subnets/Motion/subnet_5\n",
      "Accuracy subnet 5 meet is 88.89 %\n",
      "INFO:tensorflow:Restoring parameters from /home/nathan/Documents/FYP_code/LSTM1_guillermo/grouping_2/saved_sessions/subnets/Motion/subnet_6\n",
      "Accuracy subnet 6 open is 89.69 %\n",
      "INFO:tensorflow:Restoring parameters from /home/nathan/Documents/FYP_code/LSTM1_guillermo/grouping_2/saved_sessions/subnets/Motion/subnet_7\n",
      "Accuracy subnet 7 pour is 77.36 %\n",
      "INFO:tensorflow:Restoring parameters from /home/nathan/Documents/FYP_code/LSTM1_guillermo/grouping_2/saved_sessions/subnets/Motion/subnet_8\n",
      "Accuracy subnet 8 prick is 87.50 %\n",
      "INFO:tensorflow:Restoring parameters from /home/nathan/Documents/FYP_code/LSTM1_guillermo/grouping_2/saved_sessions/subnets/Motion/subnet_9\n",
      "Accuracy subnet 9 sprinkle is 72.73 %\n",
      "INFO:tensorflow:Restoring parameters from /home/nathan/Documents/FYP_code/LSTM1_guillermo/grouping_2/saved_sessions/subnets/Motion/subnet_10\n",
      "Accuracy subnet 10 insert is 70.37 %\n",
      "INFO:tensorflow:Restoring parameters from /home/nathan/Documents/FYP_code/LSTM1_guillermo/grouping_2/saved_sessions/subnets/Motion/subnet_11\n",
      "Accuracy subnet 11 takeout is 71.05 %\n",
      "INFO:tensorflow:Restoring parameters from /home/nathan/Documents/FYP_code/LSTM1_guillermo/grouping_2/saved_sessions/subnets/Motion/subnet_12\n",
      "Accuracy subnet 12 squeeze is 62.50 %\n",
      "\n",
      " Assuming groupRNN is 100% perfect, accuracy of subnets only: 81.20 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Analyze overall architecture group+subnet results\n",
    "\n",
    "#Helps to know what is left to compute\n",
    "print('Now using subnets for groups ' + str(groups_with_subnet))\n",
    "\n",
    "#Assume groupRNN 100% pred and evaluate subnet results\n",
    "correct_pred_with = []\n",
    "group_test_labels = [atog[value] for value in test_labels] #convert to group number for comparison\n",
    "for group_number in groups_with_subnet:\n",
    "    correct_pred = useSubnet(group_number, group_test_labels, test_data, test_labels, test_lengths)\n",
    "    correct_pred_with = np.append(correct_pred_with, correct_pred) #accumulate results\n",
    "correct_pred_with_accuracy = np.mean(correct_pred_with)\n",
    "print('\\n Assuming groupRNN is 100%% perfect, accuracy of subnets only: %.2f %% \\n' % float(100*correct_pred_with_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass groupRNN output through subnets and collect results\n",
    "correct_pred_with = []\n",
    "for group_number in groups_with_subnet:\n",
    "    correct_pred = useSubnet(group_number, pred_labels, test_data, test_labels, test_lengths)\n",
    "    correct_pred_with = np.append(correct_pred_with, correct_pred) #accumulate results   \n",
    "correct_pred_with_accuracy = np.mean(correct_pred_with)\n",
    "print('Using groupRNN output, accuracy of subnets only: %.2f %%' % float(100*correct_pred_with_accuracy)) \n",
    "#above should be same as below if no 1 action groups\n",
    "\n",
    "#Final result\n",
    "final_pred = np.append(correct_pred_without, correct_pred_with) #add previously known results (groups with 1 action)\n",
    "final_accuracy = np.mean(final_pred)\n",
    "print('Final group+subnet accuracy: %.2f %%' % float(100*final_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
